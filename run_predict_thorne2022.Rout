
R version 4.1.1 (2021-08-10) -- "Kick Things"
Copyright (C) 2021 The R Foundation for Statistical Computing
Platform: x86_64-pc-linux-gnu (64-bit)

R is free software and comes with ABSOLUTELY NO WARRANTY.
You are welcome to redistribute it under certain conditions.
Type 'license()' or 'licence()' for distribution details.

  Natural language support but running in an English locale

R is a collaborative project with many contributors.
Type 'contributors()' for more information and
'citation()' on how to cite R or R packages in publications.

Type 'demo()' for some demos, 'help()' for on-line help, or
'help.start()' for an HTML browser interface to help.
Type 'q()' to quit R.

> ## R script to run the HM models predicting daily butterfly species occurence
> library(rstan)
Loading required package: StanHeaders
Loading required package: ggplot2
rstan (Version 2.21.3, GitRev: 2e1f913d3ca3)
For execution on a local, multicore CPU with excess RAM we recommend calling
options(mc.cores = parallel::detectCores()).
To avoid recompilation of unchanged Stan programs, we recommend calling
rstan_options(auto_write = TRUE)
> rstan_options(auto_write = TRUE)
> options(mc.cores = parallel::detectCores())
> library(scales)
> library(fields)
Loading required package: spam
Spam version 2.8-0 (2022-01-05) is loaded.
Type 'help( Spam)' or 'demo( spam)' for a short introduction 
and overview of this package.
Help for individual functions is also obtained by adding the
suffix '.spam' to the function name, e.g. 'help( chol.spam)'.

Attaching package: ‘spam’

The following objects are masked from ‘package:base’:

    backsolve, forwardsolve

Loading required package: viridis
Loading required package: viridisLite

Attaching package: ‘viridis’

The following object is masked from ‘package:scales’:

    viridis_pal


Try help(fields) to get started.
> 
> ## helper functions
> stand<-function(x=NA){
+ 	x<-(x-mean(x,na.rm=TRUE))/sd(x,na.rm=TRUE)
+ 	return(x)
+ }
> 
> standNew<-function(x=NA,newx){
+ 	newx<-(newx-mean(x,na.rm=TRUE))/sd(x,na.rm=TRUE)
+ 	return(newx)
+ }
> 
> 
> 
> ## read in the data
> dat<-read.csv("thorneCastData2022.csv")
> ndat<-read.csv("thorneCastData2022_April.csv")
> 
> table(dat$site_name)

  Castle Peak   Donner Pass Lang Crossing Sierra Valley    Washington 
        41890        103477        102832        101514        108523 
> 
> #  Castle Peak   Donner Pass Lang Crossing Sierra Valley    Washington 
> #        41890        103477        102832        101514        108523
> 
> sites<-unique(dat$site_name)
> myargs<-commandArgs(trailingOnly=TRUE)
> j<-as.numeric(myargs[1])
> 
> cat("working on site",sites[j],"\n")
working on site Washington 
> sub_dat<-dat[dat$site_name==sites[j],]
> sub_ndat<-ndat[ndat$site_name==sites[j],]
> spKeep<-names(which(tapply(sub_dat$pa,INDEX=sub_dat$genus_species,sum) > 10))
> sub_dat<-sub_dat[ (sub_dat$genus_species %in% spKeep),]
> sp<-unique(sub_dat$genus_species)
> bb<-as.matrix(cbind(stand(sub_dat$PrevFall_tmn),stand(sub_dat$PrevFall_ppt),stand(sub_dat$Win_tmn),stand(sub_dat$pck),stand(sub_dat$ordDate),stand(sub_dat$ordDate)^2,stand(sub_dat$Year)))
> bbi<-as.matrix(cbind(bb,bb[,4]*bb[,5],bb[,4]*bb[,6]))
> dmin<-min(sub_dat$ordDat)
> dmax<-max(sub_dat$ordDat)
> ndays<-dmin:dmax
> ndays<-standNew(sub_dat$ordDat,ndays)
> nD<-length(ndays)
> nSp<-length(sp)
> b1<-standNew(sub_dat$PrevFall_tmn,sub_ndat$PrevFall_tmn)
> b2<-standNew(sub_dat$PrevFall_ppt,sub_ndat$PrevFall_ppt)
> b3<-standNew(sub_dat$Win_tmn,sub_ndat$Win_tmn)
> b4<-standNew(sub_dat$pck,sub_ndat$pck)
> b7<-standNew(sub_dat$Year,sub_ndat$Year)
> nbb<-as.matrix(cbind(rep(b1,nD*nSp),rep(b2,nD*nSp),rep(b3,nD*nSp),rep(b4,nD*nSp),rep(ndays,nSp),rep(ndays^2,nSp),rep(b7,nD*nSp)))
> nbbi<-as.matrix(cbind(nbb,nbb[,4]*nbb[,5],nbb[,4]*nbb[,6]))
> newSp<-rep(sp,each=nD)
> D<-list(X=bbi,N=dim(bbi)[1],K=9,L=length(sp),y=sub_dat$pa,ll=as.numeric(as.factor(sub_dat$genus_species)),newX=nbbi,newN=dim(nbbi)[1],newll=as.numeric(as.factor(newSp)))
> fit<-stan("hmodel_forecast.stan",data=D,iter=4000,warmup=2000) ## default is warmup = 1/2 iter

SAMPLING FOR MODEL 'hmodel_forecast' NOW (CHAIN 1).

SAMPLING FOR MODEL 'hmodel_forecast' NOW (CHAIN 2).

SAMPLING FOR MODEL 'hmodel_forecast' NOW (CHAIN 3).

SAMPLING FOR MODEL 'hmodel_forecast' NOW (CHAIN 4).
CChain 1: 
Chain 1: Gradient evaluation took 0.02 seconds
Chain 1: 1000 transitions using 10 leapfrog steps per transition would take 200 seconds.
Chain 1: Adjust your expectations accordingly!
Chain 1: 
Chain 1: CChain 3: 
Chain 3: Gradient evaluation took 0.03 seconds
Chain 3: 1000 transitions using 10 leapfrog steps per transition would take 300 seconds.
Chain 3: Adjust your expectations accordingly!
Chain 3: 
Chain 3: Chain 4: 
Chain 4: Gradient evaluation took 0.02 seconds
Chain 4: 1000 transitions using 10 leapfrog steps per transition would take 200 seconds.
Chain 4: Adjust your expectations accordingly!
Chain 4: 
Chain 4: 
Chain 2: 
Chain 2: Gradient evaluation took 0.03 seconds
Chain 2: 1000 transitions using 10 leapfrog steps per transition would take 300 seconds.
Chain 2: Adjust your expectations accordingly!
Chain 2: 
Chain 2: 
CChain 1: Iteration:    1 / 4000 [  0%]  (Warmup)CChain 3: Iteration:    1 / 4000 [  0%]  (Warmup)Chain 4: Iteration:    1 / 4000 [  0%]  (Warmup)
Chain 2: Iteration:    1 / 4000 [  0%]  Chain 2: Chain 2: Iteration:  400 / 4000 [ 10%]  (Warmup)
Chain 3: Iteration:  400 / 4000 [ 10%]  (Warmup)
Chain 4: Iteration:  400 / 4000 [ 10%]  (Warmup)
Chain 1: Iteration:  400 / 4000 [ 10%]  (Warmup)
Chain 2: Iteration:  800 / 4000 [ 20%]  (Warmup)
Chain 3: Iteration:  800 / 4000 [ 20%]  (Warmup)
Chain 1: Iteration:  800 / 4000 [ 20%]  (Warmup)
Chain 4: Iteration:  800 / 4000 [ 20%]  (Warmup)
Chain 2: Iteration: 1200 / 4000 [ 30%]  (Warmup)
Chain 3: Iteration: 1200 / 4000 [ 30%]  (Warmup)
Chain 1: Iteration: 1200 / 4000 [ 30%]  (Warmup)
Chain 4: Iteration: 1200 / 4000 [ 30%]  (Warmup)
Chain 2: Iteration: 1600 / 4000 [ 40%]  (Warmup)
Chain 3: Iteration: 1600 / 4000 [ 40%]  (Warmup)
Chain 4: Iteration: 1600 / 4000 [ 40%]  (Warmup)
Chain 1: Iteration: 1600 / 4000 [ 40%]  (Warmup)
Chain 3: Iteration: 2000 / 4000 [ 50%]  (Warmup)
Chain 3: Iteration: 2001 / 4000 [ 50%]  (Sampling)
Chain 2: Iteration: 2000 / 4000 [ 50%]  (Warmup)
Chain 2: Iteration: 2001 / 4000 [ 50%]  (Sampling)
Chain 4: Iteration: 2000 / 4000 [ 50%]  (Warmup)
Chain 4: Iteration: 2001 / 4000 [ 50%]  (Sampling)
Chain 1: Iteration: 2000 / 4000 [ 50%]  (Warmup)
Chain 1: Iteration: 2001 / 4000 [ 50%]  (Sampling)
Chain 4: Iteration: 2400 / 4000 [ 60%]  (Sampling)
Chain 1: Iteration: 2400 / 4000 [ 60%]  (Sampling)
Chain 2: Iteration: 2400 / 4000 [ 60%]  (Sampling)
Chain 3: Iteration: 2400 / 4000 [ 60%]  (Sampling)
Chain 4: Iteration: 2800 / 4000 [ 70%]  (Sampling)
Chain 1: Iteration: 2800 / 4000 [ 70%]  (Sampling)
Chain 2: Iteration: 2800 / 4000 [ 70%]  (Sampling)
Chain 4: Iteration: 3200 / 4000 [ 80%]  (Sampling)
Chain 1: Iteration: 3200 / 4000 [ 80%]  (Sampling)
Chain 3: Iteration: 2800 / 4000 [ 70%]  (Sampling)
Chain 4: Iteration: 3600 / 4000 [ 90%]  (Sampling)
Chain 1: Iteration: 3600 / 4000 [ 90%]  (Sampling)
Chain 2: Iteration: 3200 / 4000 [ 80%]  (Sampling)
Chain 3: Iteration: 3200 / 4000 [ 80%]  (Sampling)
Chain 4: Iteration: 4000 / 4000 [100%]  (Sampling)
Chain 4: 
Chain 4:  Elapsed Time: 2616.39 seconds (Warm-up)
Chain 4:                1737.96 seconds (Sampling)
Chain 4:                4354.35 seconds (Total)
Chain 4: 
Chain 1: Iteration: 4000 / 4000 [100%]  (Sampling)
Chain 1: 
Chain 1:  Elapsed Time: 2630.66 seconds (Warm-up)
Chain 1:                1740.01 seconds (Sampling)
Chain 1:                4370.67 seconds (Total)
Chain 1: 
Chain 2: Iteration: 3600 / 4000 [ 90%]  (Sampling)
Chain 3: Iteration: 3600 / 4000 [ 90%]  (Sampling)
Chain 2: Iteration: 4000 / 4000 [100%]  (Sampling)
Chain 2: 
Chain 2:  Elapsed Time: 2519.63 seconds (Warm-up)
Chain 2:                2564.44 seconds (Sampling)
Chain 2:                5084.07 seconds (Total)
Chain 2: 
Chain 3: Iteration: 4000 / 4000 [100%]  (Sampling)
Chain 3: 
Chain 3:  Elapsed Time: 2512.56 seconds (Warm-up)
Chain 3:                2789.99 seconds (Sampling)
Chain 3:                5302.55 seconds (Total)
Chain 3: 
> 
> save(list=ls(),file=paste("thorne2022_",sites[j],".rdat",sep=""))
> 	
> spid<-as.numeric(as.factor(sub_dat$genus_species))
> nspid<-as.numeric(as.factor(newSp))
> 
> pac<-tapply(INDEX=sub_dat$genus_species,X=sub_dat$pa,sum)
> 
> mn<-mean(sub_dat$ordDate)
> sdd<-sd(sub_dat$ordDate)
> od<-(nbbi[,5]*sdd)+mn
> odd<-as.Date(sprintf("%05d", 22000+od), format = "%y%j")
> 
> 
> ## plots of posteriors
> ppA<-extract(fit,par="pp")[[1]]
> ppB<-extract(fit,par="beta")[[1]]
> nppA<-extract(fit,par="ppNew")[[1]]
> brks<-quantile(bb[,4],probs=seq(0,1,1/18))
> cs<-rev(heat.colors(n=18))
> css<-rep(cs[1],length(spid))
> for(i in 2:18){
+         css[bb[,4] > brks[i]]<-cs[i]
+ }
> 
> pdf(paste("bayThHglm_2022_fit_",sites[j],".pdf",sep=""),width=9,height=12)
> par(mfrow=c(4,3))
> par(mar=c(4.5,5.5,2.5,1.5))
> med_PA<-apply(ppA,2,median)
> for(i in 1:length(sp)){
+         a<-which(spid==i)
+        	plot(bbi[a,5],med_PA[a],pch=19,xlab="Day",ylab="Prob. present",col=alpha(css[a],0.9),cex.lab=1.4)
+ 	        title(main=sp[i],cex.main=1.4)
+ }
> dev.off()
null device 
          1 
> 	
> pdf(paste("bayThHglm_2022_forecast_",sites[j],".pdf",sep=""),width=9,height=12)
> par(mfrow=c(4,3))
> par(mar=c(4.5,5.5,2.5,1.5))
> med_PA<-apply(nppA,2,median)
> lb_PA<-apply(nppA,2,quantile,probs=0.05)
> ub_PA<-apply(nppA,2,quantile,probs=0.95)
> for(i in 1:length(sp)){
+         a<-which(nspid==i)
+        	plot(od[a],med_PA[a],pch=19,xlab="Day",ylab="Prob. present",col=alpha("darkgray",0.9),ylim=c(0,1),cex.lab=1.4,type='n')
+ 	polygon(c(od[a],rev(od[a])),c(lb_PA[a],rev(ub_PA[a])),col=alpha("darkgray",.4),border=NA)
+ 	lines(od[a],med_PA[a],col=alpha("darkgray",0.9),lwd=1.8)
+         title(main=sp[i],cex.main=1.4)
+ }
> dev.off()
null device 
          1 
> 
> null_PA<-matrix(NA,nrow=length(unique(odd)),ncol=8000)
> for(i in 1:8000){ ## 8000 HMC samples
+ 	sam_PA<-rbinom(n=length(med_PA),size=1,nppA[i,])
+ 	null_PA[,i]<-tapply(X=sam_PA,INDEX=odd,sum)
+ }
> lb<-apply(null_PA,1,quantile,probs=0.05)
> ub<-apply(null_PA,1,quantile,probs=0.95)
> 
> pdf(paste("bayThHglm_2022_forecast_spec_",sites[j],".pdf",sep=""),width=4.5,height=4.5)
> par(mar=c(4.5,4.5,.5,.5))
> plot(sort(unique(odd)),tapply(X=med_PA,INDEX=odd,sum),type='n',xlab="Date",ylab="Number of species",col=alpha("darkgray",0.9),cex.lab=1.2,ylim=c(0,1.02*max(ub)))
> polygon(c(sort(unique(odd)),rev(sort(unique(odd)))),c(lb,rev(ub)),col=alpha("darkgray",.4),border=NA)
> lines(sort(unique(odd)),tapply(X=med_PA,INDEX=odd,sum),lwd=1.8,col=alpha("darkgray",0.9))
> dev.off()
null device 
          1 
> 
> ppM<-matrix(NA,nrow=nSp,ncol=nD)
> for(i in 1:nSp){
+ 	a<-which(nspid==i)
+         ppM[i,]<-med_PA[a][order(od[a])]
+ }
> colTab<-rev(heat.colors(10))
> pdf(paste("bayThHglm_2022_forecast_all_",sites[j],".pdf",sep=""),width=6,height=4.5)
> par(mar=c(4.5,4.5,.5,.5))
> image.plot(t(ppM[rev(order(apply(ppM,1,which.max))),]),xlab="Date",ylab="",axes=FALSE,cex.lab=1.2,col=colTab)
> axis(2,at=((1:nSp)-1)/nSp,sp[rev(order(apply(ppM,1,which.max)))],las=2,cex.axis=.2)
> sdy<-seq(1,nD,7)
> axis(1,at=sdy/nD,sort(unique(format(odd,format="%m-%d")))[sdy],las=2,cex.axis=.7)
> box()
> dev.off()
null device 
          1 
> 
> 
> med<-apply(ppB,c(2,3),median)
> lb<-apply(ppB,c(2,3),quantile,probs=0.05)
> ub<-apply(ppB,c(2,3),quantile,probs=0.95)
> pdf(paste("effectsTh_2022_",sites[j],".pdf",sep=""),width=9,height=9)
> par(mar=c(4.5,5.5,2.5,1.5))
> covnms<-c("Fall_tmn","Fall_ppt","Win_tmn","Pack","Day","Day_2","Year","Pack-Day","Pack-Day_2")
> par(mfrow=c(3,3))
> for(i in 1:9){
+   	plot(med[,i],xlab="Species",ylab="Coefficient",pch=19,col=alpha("gray20",.8),
+         ylim=c(min(lb[,i]),max(ub[,i])),cex.lab=1.4)
+ 	abline(h=0,lty=2)
+ 	segments(1:58,lb[,i],1:58,ub[,i])
+ 	title(covnms[i],cex.main=1.4)
+ }
> dev.off()
null device 
          1 
> 
> pdf(paste("hier_effectsTh_2022_",sites[j],".pdf",sep=""),width=5,height=6)
> par(mar=c(4.5,5.5,2.5,1.5))
> plot(fit,pars="mu",cex.axis=1.2)
ci_level: 0.8 (80% intervals)
outer_level: 0.95 (95% intervals)
> plot(fit,pars="sigma",cex.axis=1.2)
ci_level: 0.8 (80% intervals)
outer_level: 0.95 (95% intervals)
> dev.off()
null device 
          1 
> 
> save(list=ls(),file=paste("thorne2022_",sites[j],".rdat",sep=""))
> 
> proc.time()
     user    system   elapsed 
22245.309   188.311  8588.437 
 
